---
title: "lbb-classification-2"
author: "Alfan"
date: "2/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import Library

```{r message=FALSE}
# Data wrangling Library
library(tidyverse)
library(dplyr) 
# Visualize data
library(ggplot2)
library(inspectdf)
library(GGally)
library(plotly)
# Naive Bayes 
library(e1071)
# Splitting Data
library(rsample)
# Random Forest
library(randomForest)
# Smote for unbalanced data
library(DMwR)
# ROCR
library(ROCR)
# Confussion Matrix
library(caret)
# Decision Tree
library(partykit)
```


# Import Function 
```{r}
source("matrix_result.R")
source("metrics.R")
```


```{r}
telemark <- read_csv2("data/bank-full.csv")
```
 
```{r}
glimpse(telemark)
```
Input variables:   
1. `age`: age (numeric)   
2. `job` : type of job (categorical: "admin.","unknown","unemployed","management","housemaid","entrepreneur","student", "blue-collar","self-employed","retired","technician","services")  
3. `marital` : marital status (categorical: "married","divorced","single"; note: "divorced" means divorced or widowed)   
4. `education` : education (categorical: "unknown","secondary","primary","tertiary")   
5. `default`: has credit in default? (binary: "yes","no")   
6. `balance`: average yearly balance, in euros (numeric)   
7. `housing`: has housing loan? (binary: "yes","no")   
8. `loan`: has personal loan? (binary: "yes","no")   
9. `contact`: contact communication type (categorical: "unknown","telephone","cellular")    
10. `day`: last contact day of the month (numeric)   
11. `month`: last contact month of year (categorical: "jan", "feb", "mar", ..., "nov", "dec")   
12. `duration`: last contact duration, in seconds (numeric)   
13. `campaign`: number of contacts performed during this campaign and for this client (numeric, includes last contact)   
14. `pdays`: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)   
15. `previous`: number of contacts performed before this campaign and for this client (numeric)   
16. `poutcome`: outcome of the previous marketing campaign (categorical: "unknown","other","failure","success")   
17. `y`: has the client subscribed a term deposit? (binary: "yes","no")




```{r}
table(is.na(telemark))
```
 
```{r}
telemark <- telemark %>% 
  mutate(job = as.factor(job),
         marital = as.factor(marital),
         education = as.factor(education),
         default = as.factor(default),
         housing = as.factor(housing),
         loan = as.factor(loan),
         contact = as.factor(contact),
         month = as.factor(month),
         poutcome = as.factor(poutcome),
         subscribe = as.factor(y)) %>% 
  select(-c(y))
```

# Exploratory Data Analysis

```{r}
summary(telemark)
```


```{r}
show_plot(inspect_cor(subset(telemark, select = -c(subscribe))))
```

```{r}
ggcorr(telemark, label = T)
```


```{r}
numericCols <- unlist(lapply(telemark, is.numeric))
show_plot(inspect_num(telemark[,numericCols]))
```

```{r}
prop.table(table(telemark$subscribe))
```


```{r}
set.seed(1)
split <- initial_split(data = telemark, prop = 0.8, strata = subscribe)
telemark_train <- training(split)
telemark_test <- testing(split)
```

```{r}
prop.table(table(telemark_train$subscribe))
```

```{r}
# telemark_train_upsample <- upSample(x = telemark_train[, -17], y = telemark_train$subscribe, yname = "subscribe")
telemark_train_upsample <- SMOTE(subscribe ~ ., as.data.frame(telemark_train), perc.over = 100, perc.under = 200)
```

```{r}
prop.table(table(telemark_train_upsample$subscribe))
```


```{r}
model_naive <- naiveBayes(subscribe ~ ., data = telemark_train_upsample)
```

```{r}
naive_prediction <- predict(model_naive, telemark_test)
naive_prediction_raw <- as.data.frame(predict(model_naive, telemark_test, type = "raw"))

naive_prediction_raw <- naive_prediction_raw %>%
  mutate(no = round(no,4),
         yes = round(yes,4))
```


```{r}
naive_matrix <- confusionMatrix(naive_prediction, telemark_test$subscribe, positive = "yes")
table <- as.table(naive_matrix)
table <- as.data.frame(table)

table %>% ggplot(aes(x = Prediction, y = Reference, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), fontface = "bold", color = "white") +
  theme_minimal() +
  theme(legend.position = "none")
```

```{r}
naive_matrix <- matrix_result(naive_matrix, "Naive Bayes")
naive_matrix
```

```{r}
# ROC
naive_roc <- data.frame(prediction = naive_prediction_raw[,2],
                        trueclass = as.numeric(telemark_test$subscribe=="yes"))
head(naive_roc)
```


```{r}
naive_roc_pred <- prediction(naive_roc$prediction, naive_roc$trueclass) 

# ROC curve
plot(performance(naive_roc_pred, "tpr", "fpr"),
     main = "ROC")
abline(a = 0, b = 1)
```

```{r}
# AUC
auc_ROCR_n <- performance(naive_roc_pred, measure = "auc")
auc_ROCR_n <- auc_ROCR_n@y.values[[1]]
auc_ROCR_n
```



```{r}
# model tuning - metrics function
co <- seq(0.01,0.99,length=100)
result <- matrix(0,100,4)

# apply function metrics
for(i in 1:100){
  result[i,] = metrics(cutoff = co[i], 
                     prob = naive_prediction_raw$yes, 
                     ref = as.factor(ifelse(telemark_test$subscribe == "yes", 1, 0)), 
                     postarget = "1", 
                     negtarget = "0")
}

# visualize
ggplotly(tibble("Recall" = result[,1],
           "Accuracy" = result[,2],
           "Precision" = result[,3],
           "Specificity" = result[,4],
                   "Cutoff" = co) %>% 
  gather(key = "Metrics", value = "value", 1:4) %>% 
  ggplot(aes(x = Cutoff, y = value, col = Metrics)) +
  geom_line(lwd = 1.5) +
  scale_color_manual(values = c("darkred","darkgreen","orange", "blue")) +
  scale_y_continuous(breaks = seq(0,1,0.1), limits = c(0,1)) +
  scale_x_continuous(breaks = seq(0,1,0.1)) +
  labs(title = "Tradeoff Model Perfomance") +
  theme_minimal() +
  theme(legend.position = "top",
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank()))
```

```{r}
#Tuning Threshold
naive_prediction_tuning <- naive_prediction_raw %>%
  mutate(label = as.factor(ifelse(yes >= 0.65, "yes", "no"))) %>% 
  select(label)
```


```{r}
naive_matrix_tuning <- confusionMatrix(naive_prediction_tuning$label, naive_prediction, positive = "yes")
naive_matrix <- matrix_result(naive_matrix_tuning, "Naive Bayes Tuning")
naive_matrix
```

```{r}
model_dtree <- ctree(subscribe ~ ., telemark_train_upsample)
```

```{r}
dtree_prediction <- predict(model_dtree, telemark_test)
```

```{r}
dtree_matrix <- confusionMatrix(dtree_prediction, telemark_test$subscribe, positive = "yes")
dtree_matrix <- matrix_result(dtree_matrix, "Decision Tree")
dtree_matrix
```

```{r}
model_dtree_tuning <- ctree(subscribe ~ ., telemark_train_upsample,
                            control = ctree_control(mincriterion = 0.1, minsplit = 100, minbucket = 60))

dtree_prediction_tuning <- predict(model_dtree_tuning, telemark_test)
```

```{r}
dtree_matrix_tuning <- confusionMatrix(dtree_prediction_tuning, telemark_test$subscribe)
dtree_matrix_tuning <- matrix_result(dtree_matrix_tuning, "Decision Tree Tuning")
dtree_matrix_tuning
```

```{r}
ctrl <- trainControl(method = "repeatedcv", number = 5,repeats = 3)
```

```{r}
# model_rforest <- train(subscribe ~ ., data = telemark_train_upsample, method = "rf", trControl = ctrl, ntree = 100)
# saveRDS(model_rforest, file = "model_rforest.RDS")
model_rforest <- readRDS("model_rforest.RDS")
```

```{r}
rforest_predict <- predict(model_rforest, telemark_test)
rforest_predict_raw <- predict(model_rforest, telemark_test, type = "prob")
```

```{r}
plot(model_rforest$finalModel)
legend("topright", colnames(model_rforest$finalModel$err.rate),col=1:6,cex=0.8,fill=1:6)
```


```{r}
rforest_matrix <- confusionMatrix(rforest_predict, telemark_test$subscribe, positive = "yes")
table <- as.table(rforest_matrix)
table <- as.data.frame(table)

table %>% ggplot(aes(x = Prediction, y = Reference, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), fontface = "bold", color = "white") +
  theme_minimal() +
  theme(legend.position = "none")
```


```{r}
rforest_matrix <- matrix_result(rforest_matrix, "Random Forest")
rforest_matrix
```


```{r}
# ROC
forest_roc <- data.frame(prediction = rforest_predict_raw[,2],
                        trueclass = as.numeric(telemark_test$subscribe=="yes"))
head(forest_roc)
```


```{r}
forest_rocz_prediction <- prediction(forest_roc$prediction, forest_roc$trueclass) 

# ROC curve
plot(performance(forest_rocz_prediction, "tpr", "fpr"),
     main = "ROC")
abline(a = 0, b = 1)
```

```{r}
# AUC
auc_ROCR_n <- performance(forest_rocz_prediction, measure = "auc")
auc_ROCR_n <- auc_ROCR_n@y.values[[1]]
auc_ROCR_n
```



```{r}
co <- seq(0.01,0.99,length=100)
result <- matrix(0,100,4)

# apply function metrics
for(i in 1:100){
  result[i,] = metrics(cutoff = co[i], 
                     prob = rforest_predict_raw$yes, 
                     ref = as.factor(ifelse(telemark_test$subscribe == "yes", 1, 0)), 
                     postarget = "1", 
                     negtarget = "0")
}

# visualize
ggplotly(tibble("Recall" = result[,1],
           "Accuracy" = result[,2],
           "Precision" = result[,3],
           "Specificity" = result[,4],
                   "Cutoff" = co) %>% 
  gather(key = "Metrics", value = "value", 1:4) %>% 
  ggplot(aes(x = Cutoff, y = value, col = Metrics)) +
  geom_line(lwd = 1.5) +
  scale_color_manual(values = c("darkred","darkgreen","orange", "blue")) +
  scale_y_continuous(breaks = seq(0,1,0.1), limits = c(0,1)) +
  scale_x_continuous(breaks = seq(0,1,0.1)) +
  labs(title = "Tradeoff Model Perfomance") +
  theme_minimal() +
  theme(legend.position = "top",
        panel.grid.minor.y = element_blank(),
        panel.grid.minor.x = element_blank()))
```


```{r}
#Tuning Threshold
rforest_predict_tuning <- rforest_predict_raw %>%
  mutate(label = as.factor(ifelse(yes >= 0.52, "yes", "no"))) %>% 
  select(label)
```


```{r}
rforest_matrix_tuning <- confusionMatrix(naive_prediction_tuning$label, naive_prediction, positive = "yes")
rforest_matrix_tuning <- matrix_result(rforest_matrix_tuning, "Random Forest Tuning")
rforest_matrix_tuning
```



